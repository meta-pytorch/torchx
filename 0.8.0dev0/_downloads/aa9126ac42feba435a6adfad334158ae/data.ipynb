{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install torchx\n!wget --no-clobber https://github.com/meta-pytorch/torchx/archive/refs/heads/main.tar.gz\n!tar xf main.tar.gz --strip-components=1\n\nNOTEBOOK = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nTrainer Datasets Example\n========================\n\nThis is the datasets used for the training example. It's using PyTorch Lightning\nlibraries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os.path\nimport tarfile\nfrom typing import Callable, Optional\n\nimport fsspec\nimport numpy\nimport pytorch_lightning as pl\nfrom PIL import Image\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets.folder import is_image_file\nfrom tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This uses torchvision to define a dataset that we will then later use in our\nPytorch Lightning data module.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class ImageFolderSamplesDataset(datasets.ImageFolder):\n    \"\"\"\n    ImageFolderSamplesDataset is a wrapper around ImageFolder that allows you to\n    limit the number of samples.\n    \"\"\"\n\n    def __init__(\n        self,\n        root: str,\n        transform: Optional[Callable[..., object]] = None,\n        num_samples: Optional[int] = None,\n        **kwargs: object,\n    ) -> None:\n        \"\"\"\n        Args:\n            num_samples: optional. limits the size of the dataset\n        \"\"\"\n        super().__init__(root, transform=transform)\n        self.num_samples = num_samples\n\n    def __len__(self) -> int:\n        if self.num_samples is not None:\n            return self.num_samples\n        return super().__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For easy of use, we define a lightning data module so we can reuse it across\nour trainer and other components that need to load data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class TinyImageNetDataModule(pl.LightningDataModule):\n    \"\"\"\n    TinyImageNetDataModule is a pytorch LightningDataModule for the tiny\n    imagenet dataset.\n    \"\"\"\n\n    # pyre-fixme[13]: Attribute `test_ds` is never initialized.\n    train_ds: ImageFolderSamplesDataset\n    # pyre-fixme[13]: Attribute `train_ds` is never initialized.\n    val_ds: ImageFolderSamplesDataset\n    # pyre-fixme[13]: Attribute `val_ds` is never initialized.\n    test_ds: ImageFolderSamplesDataset\n\n    def __init__(\n        self, data_dir: str, batch_size: int = 16, num_samples: Optional[int] = None\n    ) -> None:\n        super().__init__()\n        self.data_dir = data_dir\n        self.batch_size = batch_size\n        self.num_samples = num_samples\n\n    def setup(self, stage: Optional[str] = None) -> None:\n        # Setup data loader and transforms\n        img_transform = transforms.Compose(\n            [\n                transforms.ToTensor(),\n            ]\n        )\n        self.train_ds = ImageFolderSamplesDataset(\n            root=os.path.join(self.data_dir, \"train\"),\n            transform=img_transform,\n            num_samples=self.num_samples,\n        )\n        self.val_ds = ImageFolderSamplesDataset(\n            root=os.path.join(self.data_dir, \"val\"),\n            transform=img_transform,\n            num_samples=self.num_samples,\n        )\n        self.test_ds = ImageFolderSamplesDataset(\n            root=os.path.join(self.data_dir, \"test\"),\n            transform=img_transform,\n            num_samples=self.num_samples,\n        )\n\n    def train_dataloader(self) -> DataLoader:\n        return DataLoader(self.train_ds, batch_size=self.batch_size)\n\n    def val_dataloader(self) -> DataLoader:\n        return DataLoader(self.val_ds, batch_size=self.batch_size)\n\n    def test_dataloader(self) -> DataLoader:\n        return DataLoader(self.test_ds, batch_size=self.batch_size)\n\n    def teardown(self, stage: Optional[str] = None) -> None:\n        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To pass data between the different components we use fsspec which allows us to\nread/write to cloud or local file storage.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def download_data(remote_path: str, tmpdir: str) -> str:\n    \"\"\"\n    download_data downloads the training data from the specified remote path via\n    fsspec and places it in the tmpdir unextracted.\n    \"\"\"\n    if os.path.isdir(remote_path):\n        print(\"dataset path is a directory, using as is\")\n        return remote_path\n\n    tar_path = os.path.join(tmpdir, \"data.tar.gz\")\n    print(f\"downloading dataset from {remote_path} to {tar_path}...\")\n    fs, _, rpaths = fsspec.get_fs_token_paths(remote_path)\n    assert len(rpaths) == 1, \"must have single path\"\n    fs.get(rpaths[0], tar_path)\n\n    data_path = os.path.join(tmpdir, \"data\")\n    print(f\"extracting {tar_path} to {data_path}...\")\n    with tarfile.open(tar_path, mode=\"r\") as f:\n        f.extractall(data_path)\n\n    return data_path\n\n\ndef create_random_data(output_path: str, num_images: int = 250) -> None:\n    \"\"\"\n    Fills the given path with randomly generated 64x64 images.\n    This can be used for quick testing of the workflow of the model.\n    Does NOT pack the files into a tar, but does preprocess them.\n    \"\"\"\n    train_path = os.path.join(output_path, \"train\")\n    class1_train_path = os.path.join(train_path, \"class1\")\n    class2_train_path = os.path.join(train_path, \"class2\")\n\n    val_path = os.path.join(output_path, \"val\")\n    class1_val_path = os.path.join(val_path, \"class1\")\n    class2_val_path = os.path.join(val_path, \"class2\")\n\n    test_path = os.path.join(output_path, \"test\")\n    class1_test_path = os.path.join(test_path, \"class1\")\n    class2_test_path = os.path.join(test_path, \"class2\")\n\n    paths = [\n        class1_train_path,\n        class1_val_path,\n        class1_test_path,\n        class2_train_path,\n        class2_val_path,\n        class2_test_path,\n    ]\n\n    for path in paths:\n        try:\n            os.makedirs(path)\n        except FileExistsError:\n            pass\n\n        for i in range(num_images):\n            pixels = numpy.random.rand(64, 64, 3) * 255\n            im = Image.fromarray(pixels.astype(\"uint8\")).convert(\"RGB\")\n            im.save(os.path.join(path, f\"rand_image_{i}.jpeg\"))\n\n    process_images(output_path)\n\n\ndef process_images(img_root: str) -> None:\n    print(\"transforming images...\")\n    transform = transforms.Compose(\n        [\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,)),\n            transforms.ToPILImage(),\n        ]\n    )\n\n    image_files = []\n    for root, _, fnames in os.walk(img_root):\n        for fname in fnames:\n            path = os.path.join(root, fname)\n            if not is_image_file(path):\n                continue\n            image_files.append(path)\n    for path in tqdm(image_files, miniters=int(len(image_files) / 2000)):\n        f = Image.open(path)\n        f = transform(f)\n        f.save(path)\n\n\n# sphinx_gallery_thumbnail_path = '_static/img/gallery-lib.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}