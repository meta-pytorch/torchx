{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "!pip install torchx\n!wget --no-clobber https://github.com/meta-pytorch/torchx/archive/refs/heads/main.tar.gz\n!tar xf main.tar.gz --strip-components=1\n\nNOTEBOOK = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nData Preprocessing App Example\n====================================\n\nThis is a simple TorchX app that downloads some data via HTTP, normalizes the\nimages via torchvision and then reuploads it via fsspec.\n\nUsage\n---------\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>The datapreproc app is a single process python program, hence for\n          local runs you can run it as a regular python program: ``python ./datapreproc.py``.\n          TorchX lets you run this app on a remote cluster.</p></div>\n\nTo launch with TorchX locally (see note above) run:\n\n.. code-block:: shell-session\n\n  $ torchx run -s local_cwd utils.python       --script ./datapreproc/datapreproc.py       --       --input_path=\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"       --output_path=/tmp/torchx/datapreproc\n\n\nTo launch this app onto a remote cluster, simply specify a different scheduler\nin the ``-s`` option.\n\n.. code-block:: shell-session\n\n  $ torchx run -s kubernetes -cfg queue=foo,namespace=bar utils.python       --script ./datapreproc/datapreproc.py       --       --input_path=\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"       --output_path=/tmp/torchx/datapreproc \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import argparse\nimport os\nimport sys\nimport tarfile\nimport tempfile\nimport zipfile\nfrom typing import List\n\nimport fsspec\nfrom PIL import Image\nfrom torchvision import transforms\nfrom torchvision.datasets.folder import is_image_file\nfrom tqdm import tqdm\n\n\ndef parse_args(argv: List[str]) -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"example data preprocessing\",\n    )\n    parser.add_argument(\n        \"--input_path\",\n        type=str,\n        help=\"dataset to download\",\n        default=\"http://cs231n.stanford.edu/tiny-imagenet-200.zip\",\n    )\n    parser.add_argument(\n        \"--output_path\",\n        type=str,\n        help=\"remote path to save the .tar.gz data to\",\n        required=True,\n    )\n    parser.add_argument(\n        \"--limit\",\n        type=int,\n        help=\"limit number of processed examples\",\n    )\n    return parser.parse_args(argv)\n\n\ndef download_and_extract_zip_archive(url: str, path: str) -> None:\n    with fsspec.open(url, \"rb\") as f:\n        with zipfile.ZipFile(f, \"r\") as zip_ref:\n            zip_ref.extractall(path)\n\n\ndef main(argv: List[str]) -> None:\n    args = parse_args(argv)\n    with tempfile.TemporaryDirectory() as tmpdir:\n        print(f\"downloading {args.input_path} to {tmpdir}...\")\n        download_and_extract_zip_archive(args.input_path, tmpdir)\n\n        img_root = os.path.join(\n            tmpdir,\n            os.path.splitext(os.path.basename(args.input_path))[0],\n        )\n        print(f\"img_root={img_root}\")\n\n        print(\"transforming images...\")\n        transform = transforms.Compose(\n            [\n                transforms.ToTensor(),\n                transforms.Normalize((0.5,), (0.5,)),\n                transforms.ToPILImage(),\n            ]\n        )\n\n        image_files = []\n        for root, _, fnames in os.walk(img_root):\n            for fname in fnames:\n                path = os.path.join(root, fname)\n                if not is_image_file(path):\n                    continue\n                image_files.append(path)\n\n                if args.limit and len(image_files) > args.limit:\n                    break\n        for path in tqdm(image_files, miniters=int(len(image_files) / 2000)):\n            f = Image.open(path)\n            f = transform(f)\n            f.save(path)\n\n        tar_path = os.path.join(tmpdir, \"out.tar.gz\")\n        print(f\"packing images into {tar_path}...\")\n        with tarfile.open(tar_path, mode=\"w:gz\") as f:\n            f.add(img_root, arcname=\"\")\n\n        print(f\"uploading dataset to {args.output_path}...\")\n        fs, _, rpaths = fsspec.get_fs_token_paths(args.output_path)\n        assert len(rpaths) == 1, \"must have single output path\"\n        if fs.exists(rpaths[0]):\n            fs.rm(rpaths[0])\n        fs.put(tar_path, rpaths[0])\n\n\nif __name__ == \"__main__\" and \"NOTEBOOK\" not in globals():\n    main(sys.argv[1:])\n\n\n# sphinx_gallery_thumbnail_path = '_static/img/gallery-app.png'"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}